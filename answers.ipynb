{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Respuestas_Tarea_3_CC6204_2020",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEJLFL-H5axT"
      },
      "source": [
        "# Tarea 3: Regularización y Optimización <br/> CC6204 Deep Learning, Universidad de Chile  <br/> Hoja de respuestas\n",
        "## Nombre: \n",
        "\n",
        "**Fecha de entrega: 13 de noviembre de 2020**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54d9w9Y7XXmc"
      },
      "source": [
        "# Este notebook está pensado para correr en CoLaboratory. \n",
        "# Lo único imprescindible por importar es torch\n",
        "import torch\n",
        "\n",
        "# Posiblemenete quieras instalar e importar ipdb para debuggear.\n",
        "# Si es así, descomenta lo siguiente:\n",
        "# !pip install -q ipdb\n",
        "# import ipdb\n",
        "\n",
        "# Aqui instalamos la libreria de correccion del curso\n",
        "!pip install -U \"git+https://github.com/dccuchile/CC6204.git@master#egg=cc6204&subdirectory=autocorrect\"\n",
        "from timeit import default_timer as timer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDYIQbJuXY9U"
      },
      "source": [
        "# importamos las herramientas del curso\n",
        "from cc6204 import AutoCorrect, FailedTest\n",
        "\n",
        "# ingresa el host y port que posteamos en u-cursos\n",
        "corrector = AutoCorrect(host=\"cc6204.dcc.uchile.cl\", port=443)\n",
        "\n",
        "# anota el token que te daremos en u-cursos\n",
        "token = \"]ye/Ox;nsz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg8i3agyXDSr"
      },
      "source": [
        "# Parte 1: Regularización y Generalización\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbzcMAkOXDSr"
      },
      "source": [
        "## 1a) Regularización por *weight decay*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QfQVggvNuv9"
      },
      "source": [
        "# Tu código debiera continuar así\n",
        "class SGD():\n",
        "  def __init__(self, parameters, lr, beta=0):\n",
        "    # lo que sea necesario inicializar\n",
        "    \n",
        "    pass\n",
        "  \n",
        "  def step():\n",
        "    # actualiza acá los parámetros a partir de los gradientes\n",
        "    # y considera el nuevo valor beta\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJMKrtjZcXDH"
      },
      "source": [
        "# Tests del API del curso\n",
        "weight, grad = corrector.get_test_data(homework=3, question=\"1a\", test=1, token=token)\n",
        "\n",
        "weight = torch.tensor(weight, requires_grad=True)\n",
        "weight.grad = torch.tensor(grad)\n",
        "\n",
        "optimizer = SGD([weight], lr=0.1, beta=0.1)\n",
        "optimizer.step()\n",
        "\n",
        "# Submit\n",
        "corrector.submit(homework=3, question=\"1a\", test=1, token=token, answer=weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifPp_c1eXDSt"
      },
      "source": [
        "## 1b) Regularización por dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InfEB_1uPfcA"
      },
      "source": [
        "Para esta parte de la tarea, va a ser necesario modificar el método `forward` para que entregue el valor a la salida de la i-esima capa escondida. Para esto se modifica el método forward para que reciba un parámetro `output_layer` que indica luego de que capa escondida se espera el output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4wXj3AUXDSu"
      },
      "source": [
        "# Tu código debiera continuar como sigue\n",
        "\n",
        "class FFNN():\n",
        "  def __init__(self, F, l_h, l_a, C, keep_prob=None):\n",
        "    # debes crear los parámetros necesarios para hacer \n",
        "    # dropout en cada capa dependiendo de keep_prob\n",
        "    pass\n",
        "  \n",
        "  def forward(x, predict=False, output_layer=None):\n",
        "    # debes modificar esta función para considerar el dropout\n",
        "    # y preocuparte de no considerarlo cuando (predict=True)\n",
        "    pass\n",
        "  \n",
        "  def backward(x,y,y_pred):\n",
        "    # computar acá todos los gradientes considerando el dropout \n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrjGpVdg4xi1"
      },
      "source": [
        "# Tests del API del curso\n",
        "torch.manual_seed(0)\n",
        "sample = torch.rand(1, 10)\n",
        "red = FFNN(10, [1000], [sig], 1, keep_prob=[1.0, 0.5])\n",
        "y = red(sample, output_layer=0)\n",
        "output_mask = (y == 0)\n",
        "percent = torch.sum(output_mask).item() / list(output_mask.size())[-1]\n",
        "\n",
        "# Submit\n",
        "corrector.submit(homework=3, question=\"1b\", test=1, token=token, answer=percent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlLnZM7hi0C2"
      },
      "source": [
        "## 1c) Entrenamiento y generalización sobre MNIST "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qj1GI81izYt"
      },
      "source": [
        "# Aqui el codigo para entrenar en MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwedMCZjXDSw"
      },
      "source": [
        "# Parte 2: Optimización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nftKKxlBXDSx"
      },
      "source": [
        "## 2a) Inicialización de Xavier/He"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxEVEoeJTq81"
      },
      "source": [
        "Para los test de esta parte vamos a necesitar que modifiques tu código para que se pueda entregar valores predeterminados de `r`. Ahora tu código para las inicializaciones debe ser: `xavier_init(first_dim, second_dim, r=None)`, `he_init(first_dim, second_dim, r=None)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7DHcaQDTimb"
      },
      "source": [
        "# Tu código debiera continuar como sigue\n",
        "def xavier_init(first_dim, second_dim, r=None):\n",
        "    pass\n",
        "\n",
        "def he_init(first_dim, second_dim, r=None):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rl25Jr5UAgv"
      },
      "source": [
        "# Tests del API del curso\n",
        "r_xavier = corrector.get_test_data(homework=3, question=\"2a\", test=1, token=token)\n",
        "r_he = corrector.get_test_data(homework=3, question=\"2a\", test=2, token=token)\n",
        "\n",
        "w_xavier = xavier_init(50, 50, torch.tensor(r_xavier))\n",
        "w_he = he_init(50, 50, torch.tensor(r_he))\n",
        "\n",
        "corrector.submit(homework=3, question=\"2a\", test=1, token=token, answer=w_xavier)\n",
        "corrector.submit(homework=3, question=\"2a\", test=2, token=token, answer=w_he)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzp5SWKBXDSy"
      },
      "source": [
        "## 2b) Descenso de gradiente con momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whoBUewrUgWB"
      },
      "source": [
        "# Tu código debiera continuar así\n",
        "\n",
        "class SGD():\n",
        "  def __init__(self, parameters, lr, momentum=0):\n",
        "    # lo que sea necesario inicializar\n",
        "    \n",
        "    pass\n",
        "  \n",
        "  def step():\n",
        "    # actualiza acá los parámetros a partir de los gradientes\n",
        "    # y considerando el valor de momentum que acabámos de agregar\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WIcvmWUVl9r"
      },
      "source": [
        "# Tests del API del curso\n",
        "weight, grad = corrector.get_test_data(homework=3, question=\"2b\", test=1, token=token)\n",
        "\n",
        "weight = torch.tensor(weight, requires_grad=True)\n",
        "weight.grad = torch.tensor(grad)\n",
        "\n",
        "optimizer = SGD([weight], lr=0.1, momentum=0.9)\n",
        "optimizer.step()\n",
        "\n",
        "# Submit\n",
        "corrector.submit(homework=3, question=\"2b\", test=1, token=token, answer=weight)\n",
        "optimizer.step()\n",
        "corrector.submit(homework=3, question=\"2b\", test=2, token=token, answer=weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WNYoTIHXDS0"
      },
      "source": [
        "## 2c) RMSProp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjLGmGoXV_kG"
      },
      "source": [
        "# Tu código acá\n",
        "\n",
        "class RMSProp():\n",
        "  def __init__(self, red, lr=0.001, beta=0.9, epsilon=1e-8):\n",
        "    # en este caso debes inicializar la variable que acumula\n",
        "    # el promedio exponencial de los cuadrados\n",
        "    pass\n",
        "  \n",
        "  def step():\n",
        "    # actualiza acá los parámetros a partir de los gradientes\n",
        "    # y la corrección según S\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNnw6obOWDC4"
      },
      "source": [
        "# Tests del API del curso\n",
        "weight, grad = corrector.get_test_data(homework=3, question=\"2c\", test=1, token=token)\n",
        "\n",
        "weight = torch.tensor(weight, requires_grad=True)\n",
        "weight.grad = torch.tensor(grad)\n",
        "\n",
        "optimizer = RMSProp([weight], lr=0.001, beta=0.9, epsilon=1e-8)\n",
        "optimizer.step()\n",
        "\n",
        "# Submit\n",
        "corrector.submit(homework=3, question=\"2c\", test=1, token=token, answer=weight)\n",
        "optimizer.step()\n",
        "corrector.submit(homework=3, question=\"2c\", test=2, token=token, answer=weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJTTDpeTWTwY"
      },
      "source": [
        "## 2d) Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ola7FuFdWZH6"
      },
      "source": [
        "# Tu código acá\n",
        "\n",
        "class Adam():\n",
        "  def __init__(self, red, lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "    # en este caso debes inicializar la variable que acumula\n",
        "    # el promedio exponencial de los cuadrados\n",
        "    pass\n",
        "  \n",
        "  def step():\n",
        "    # actualiza acá los parámetros a partir de los gradientes\n",
        "    # y la corrección según S\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OdCG4RjWeMJ"
      },
      "source": [
        "# Tests del API del curso\n",
        "weight, grad = corrector.get_test_data(homework=3, question=\"2d\", test=1, token=token)\n",
        "\n",
        "weight = torch.tensor(weight, requires_grad=True)\n",
        "weight.grad = torch.tensor(grad)\n",
        "\n",
        "optimizer = Adam([weight], lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8)\n",
        "optimizer.step()\n",
        "\n",
        "# Submit\n",
        "corrector.submit(homework=3, question=\"2d\", test=1, token=token, answer=weight)\n",
        "optimizer.step()\n",
        "corrector.submit_check_some(homework=3, question=\"2d\", tests=[2, 3], token=token,\n",
        "                            answer_dict={2: weight, 3: weight}, required_number=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isKfnQt_Wszx"
      },
      "source": [
        "## 2e) Entrenamiento en MNIST \n",
        "\n",
        "Usa tu red neuronal para entrenar con los datos de MNIST y compara cómo cambian las curvas de entrenamiento dependiendo de factores como la inicialización y los algoritmos que utilices. Presenta al menos dos gráficos en donde compares. Por ejemplo, puedes presentar uno que para la misma estrategia de inicialización, los tres algoritmos de optimización para varias épocas y cómo evoluciona la pérdida y el acierto. En cada caso comenta que conclusiones puedes sacar. Algunos ejemplos de preguntas que podrías tratar de responder son:\n",
        "* ¿cómo afecta el algoritmo de optimización al tiempo de convergencia de la red para los datos de entrenamiento?\n",
        "* ¿cómo afecta el algoritmo de optimización en el acierto alcanzado por la red en los datos de prueba?\n",
        "* Si haces la parte opcional de Batch Normalization, puedes también preguntarte cosas como si aplicar, o no, BN afecta a todos los algoritmos de optimización por igual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccy31ejpWt3P"
      },
      "source": [
        "# Aqui el codigo para entrenar en MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n29s-6zXDS1"
      },
      "source": [
        "# Parte 3 (Opcional): Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytN2y-FMXDS3"
      },
      "source": [
        "# Tu código debiera continuar como sigue\n",
        "\n",
        "class FFNN():\n",
        "  def __init__(self, F, l_h, l_a, C, keep_prob=None, bn=None):\n",
        "    # debes crear los parámetros necesarios para las capas de\n",
        "    # batch normalizacion\n",
        "    pass\n",
        "  \n",
        "  def forward(x, predict=False):\n",
        "    # debes modificar esta función para considerar las capas para las que se\n",
        "    # usará batch normalization\n",
        "    # también debes preocuparte de guardar los datos estadísticos que se\n",
        "    # usaran en tiempo de test (predict=True)\n",
        "    pass\n",
        "  \n",
        "  def backward(x,y,y_pred):\n",
        "    # computar acá todos los gradientes considerando las capas de \n",
        "    # batch normalization\n",
        "    # no olvides considerar los nuevos parámetros entrenables.\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}